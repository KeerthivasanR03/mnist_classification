{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpd6QHRFbr7QjA8I0JNqRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeerthivasanR03/mnist_classification/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GCoIfjXEOb_a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone, BaseEstimator\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RtZ-tSpURN3o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9uYM6FUKQc70"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI_96IwuOvli",
        "outputId": "fa5093d0-ecad-459e-cf7a-ba19472b4894"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMRth67qO61g",
        "outputId": "2c81a70e-8e25-4af2-b356-8d578b19ad77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = np.array(mnist['data']), mnist['target']"
      ],
      "metadata": {
        "id": "EZ8bWGipO8VU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_digit = (X[0].reshape(1, -1))\n",
        "some_digit_image = some_digit.reshape(28,28)"
      ],
      "metadata": {
        "id": "Kdki_iKNPd8_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.astype(np.uint8)"
      ],
      "metadata": {
        "id": "aWajWj4QTyF7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(some_digit_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "1naZwU8LQEXK",
        "outputId": "df5959fa-e058-41f9-a373-f651ac557f9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79b27ebec460>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(plt.imshow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVPSyxshQ1AD",
        "outputId": "ad81545c-a66d-4319-e4fe-806f2ea5e316"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function imshow in module matplotlib.pyplot:\n",
            "\n",
            "imshow(X, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)\n",
            "    Display data as an image, i.e., on a 2D regular raster.\n",
            "    \n",
            "    The input may either be actual RGB(A) data, or 2D scalar data, which\n",
            "    will be rendered as a pseudocolor image. For displaying a grayscale\n",
            "    image set up the colormapping using the parameters\n",
            "    ``cmap='gray', vmin=0, vmax=255``.\n",
            "    \n",
            "    The number of pixels used to render an image is set by the Axes size\n",
            "    and the *dpi* of the figure. This can lead to aliasing artifacts when\n",
            "    the image is resampled because the displayed image size will usually\n",
            "    not match the size of *X* (see\n",
            "    :doc:`/gallery/images_contours_and_fields/image_antialiasing`).\n",
            "    The resampling can be controlled via the *interpolation* parameter\n",
            "    and/or :rc:`image.interpolation`.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    X : array-like or PIL image\n",
            "        The image data. Supported array shapes are:\n",
            "    \n",
            "        - (M, N): an image with scalar data. The values are mapped to\n",
            "          colors using normalization and a colormap. See parameters *norm*,\n",
            "          *cmap*, *vmin*, *vmax*.\n",
            "        - (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
            "        - (M, N, 4): an image with RGBA values (0-1 float or 0-255 int),\n",
            "          i.e. including transparency.\n",
            "    \n",
            "        The first two dimensions (M, N) define the rows and columns of\n",
            "        the image.\n",
            "    \n",
            "        Out-of-range RGB(A) values are clipped.\n",
            "    \n",
            "    cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
            "        The Colormap instance or registered colormap name used to map scalar data\n",
            "        to colors.\n",
            "    \n",
            "        This parameter is ignored if *X* is RGB(A).\n",
            "    \n",
            "    norm : str or `~matplotlib.colors.Normalize`, optional\n",
            "        The normalization method used to scale scalar data to the [0, 1] range\n",
            "        before mapping to colors using *cmap*. By default, a linear scaling is\n",
            "        used, mapping the lowest value to 0 and the highest to 1.\n",
            "    \n",
            "        If given, this can be one of the following:\n",
            "    \n",
            "        - An instance of `.Normalize` or one of its subclasses\n",
            "          (see :doc:`/tutorials/colors/colormapnorms`).\n",
            "        - A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc.  For a\n",
            "          list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
            "          In that case, a suitable `.Normalize` subclass is dynamically generated\n",
            "          and instantiated.\n",
            "    \n",
            "        This parameter is ignored if *X* is RGB(A).\n",
            "    \n",
            "    vmin, vmax : float, optional\n",
            "        When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
            "        the data range that the colormap covers. By default, the colormap covers\n",
            "        the complete value range of the supplied data. It is an error to use\n",
            "        *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
            "        name together with *vmin*/*vmax* is acceptable).\n",
            "    \n",
            "        This parameter is ignored if *X* is RGB(A).\n",
            "    \n",
            "    aspect : {'equal', 'auto'} or float, default: :rc:`image.aspect`\n",
            "        The aspect ratio of the Axes.  This parameter is particularly\n",
            "        relevant for images since it determines whether data pixels are\n",
            "        square.\n",
            "    \n",
            "        This parameter is a shortcut for explicitly calling\n",
            "        `.Axes.set_aspect`. See there for further details.\n",
            "    \n",
            "        - 'equal': Ensures an aspect ratio of 1. Pixels will be square\n",
            "          (unless pixel sizes are explicitly made non-square in data\n",
            "          coordinates using *extent*).\n",
            "        - 'auto': The Axes is kept fixed and the aspect is adjusted so\n",
            "          that the data fit in the Axes. In general, this will result in\n",
            "          non-square pixels.\n",
            "    \n",
            "    interpolation : str, default: :rc:`image.interpolation`\n",
            "        The interpolation method used.\n",
            "    \n",
            "        Supported values are 'none', 'antialiased', 'nearest', 'bilinear',\n",
            "        'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite',\n",
            "        'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell',\n",
            "        'sinc', 'lanczos', 'blackman'.\n",
            "    \n",
            "        If *interpolation* is 'none', then no interpolation is performed\n",
            "        on the Agg, ps, pdf and svg backends. Other backends will fall back\n",
            "        to 'nearest'. Note that most SVG renderers perform interpolation at\n",
            "        rendering and that the default interpolation method they implement\n",
            "        may differ.\n",
            "    \n",
            "        If *interpolation* is the default 'antialiased', then 'nearest'\n",
            "        interpolation is used if the image is upsampled by more than a\n",
            "        factor of three (i.e. the number of display pixels is at least\n",
            "        three times the size of the data array).  If the upsampling rate is\n",
            "        smaller than 3, or the image is downsampled, then 'hanning'\n",
            "        interpolation is used to act as an anti-aliasing filter, unless the\n",
            "        image happens to be upsampled by exactly a factor of two or one.\n",
            "    \n",
            "        See\n",
            "        :doc:`/gallery/images_contours_and_fields/interpolation_methods`\n",
            "        for an overview of the supported interpolation methods, and\n",
            "        :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
            "        a discussion of image antialiasing.\n",
            "    \n",
            "        Some interpolation methods require an additional radius parameter,\n",
            "        which can be set by *filterrad*. Additionally, the antigrain image\n",
            "        resize filter is controlled by the parameter *filternorm*.\n",
            "    \n",
            "    interpolation_stage : {'data', 'rgba'}, default: 'data'\n",
            "        If 'data', interpolation\n",
            "        is carried out on the data provided by the user.  If 'rgba', the\n",
            "        interpolation is carried out after the colormapping has been\n",
            "        applied (visual interpolation).\n",
            "    \n",
            "    alpha : float or array-like, optional\n",
            "        The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
            "        If *alpha* is an array, the alpha blending values are applied pixel\n",
            "        by pixel, and *alpha* must have the same shape as *X*.\n",
            "    \n",
            "    origin : {'upper', 'lower'}, default: :rc:`image.origin`\n",
            "        Place the [0, 0] index of the array in the upper left or lower\n",
            "        left corner of the Axes. The convention (the default) 'upper' is\n",
            "        typically used for matrices and images.\n",
            "    \n",
            "        Note that the vertical axis points upward for 'lower'\n",
            "        but downward for 'upper'.\n",
            "    \n",
            "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
            "        examples and a more detailed description.\n",
            "    \n",
            "    extent : floats (left, right, bottom, top), optional\n",
            "        The bounding box in data coordinates that the image will fill.\n",
            "        These values may be unitful and match the units of the Axes.\n",
            "        The image is stretched individually along x and y to fill the box.\n",
            "    \n",
            "        The default extent is determined by the following conditions.\n",
            "        Pixels have unit size in data coordinates. Their centers are on\n",
            "        integer coordinates, and their center coordinates range from 0 to\n",
            "        columns-1 horizontally and from 0 to rows-1 vertically.\n",
            "    \n",
            "        Note that the direction of the vertical axis and thus the default\n",
            "        values for top and bottom depend on *origin*:\n",
            "    \n",
            "        - For ``origin == 'upper'`` the default is\n",
            "          ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``.\n",
            "        - For ``origin == 'lower'`` the default is\n",
            "          ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``.\n",
            "    \n",
            "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
            "        examples and a more detailed description.\n",
            "    \n",
            "    filternorm : bool, default: True\n",
            "        A parameter for the antigrain image resize filter (see the\n",
            "        antigrain documentation).  If *filternorm* is set, the filter\n",
            "        normalizes integer values and corrects the rounding errors. It\n",
            "        doesn't do anything with the source floating point values, it\n",
            "        corrects only integers according to the rule of 1.0 which means\n",
            "        that any sum of pixel weights must be equal to 1.0.  So, the\n",
            "        filter function must produce a graph of the proper shape.\n",
            "    \n",
            "    filterrad : float > 0, default: 4.0\n",
            "        The filter radius for filters that have a radius parameter, i.e.\n",
            "        when interpolation is one of: 'sinc', 'lanczos' or 'blackman'.\n",
            "    \n",
            "    resample : bool, default: :rc:`image.resample`\n",
            "        When *True*, use a full resampling method.  When *False*, only\n",
            "        resample when the output image is larger than the input image.\n",
            "    \n",
            "    url : str, optional\n",
            "        Set the url of the created `.AxesImage`. See `.Artist.set_url`.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    `~matplotlib.image.AxesImage`\n",
            "    \n",
            "    Other Parameters\n",
            "    ----------------\n",
            "    data : indexable object, optional\n",
            "        If given, all parameters also accept a string ``s``, which is\n",
            "        interpreted as ``data[s]`` (unless this raises an exception).\n",
            "    \n",
            "    **kwargs : `~matplotlib.artist.Artist` properties\n",
            "        These parameters are passed on to the constructor of the\n",
            "        `.AxesImage` artist.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    matshow : Plot a matrix or an array as an image.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Unless *extent* is used, pixel centers will be located at integer\n",
            "    coordinates. In other words: the origin will coincide with the center\n",
            "    of pixel (0, 0).\n",
            "    \n",
            "    There are two common representations for RGB images with an alpha\n",
            "    channel:\n",
            "    \n",
            "    -   Straight (unassociated) alpha: R, G, and B channels represent the\n",
            "        color of the pixel, disregarding its opacity.\n",
            "    -   Premultiplied (associated) alpha: R, G, and B channels represent\n",
            "        the color of the pixel, adjusted for its opacity by multiplication.\n",
            "    \n",
            "    `~matplotlib.pyplot.imshow` expects RGB images adopting the straight\n",
            "    (unassociated) alpha representation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000, ], X[60000:], y[:60000], y[60000:]"
      ],
      "metadata": {
        "id": "H9xWWZs4SmKw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BinaryClassifier**"
      ],
      "metadata": {
        "id": "liMu0WtxTmgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_5 = (y_train==5)\n",
        "y_test_5 = (y_test==5)"
      ],
      "metadata": {
        "id": "7d8-rgVjTcll"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "20a9WkwjT4i1",
        "outputId": "d4cdb755-41cc-4537-81b5-8d30dbaab42a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf.predict(some_digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAIGxDiOUfh0",
        "outputId": "c55552e6-bbae-4b2a-9e81-cb8f4341b1db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
        "  clone_clf = clone(sgd_clf)\n",
        "  X_train_folds = X_train[train_index]\n",
        "  y_train_folds = y_train_5[train_index]\n",
        "  X_test_fold = X_train[test_index]\n",
        "  y_test_fold = y_train_5[test_index]\n",
        "  clone_clf.fit(X_train_folds, y_train_folds)\n",
        "  y_pred = clone_clf.predict(X_test_fold)\n",
        "  n_correct = sum(y_pred == y_test_fold)\n",
        "  print(n_correct / len(y_pred)) # prints 0.9502, 0.96565 and 0.96495"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azkBdLCuYywa",
        "outputId": "6171eb70-6bd6-41da-bd29-6f13a6c1daa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9669\n",
            "0.91625\n",
            "0.96785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')"
      ],
      "metadata": {
        "id": "E_GquC_WZe8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Never5Classifier(BaseEstimator):\n",
        "  def fit(self, X, y=None):\n",
        "    pass\n",
        "  def predict(self, X):\n",
        "    return np.zeros((len(X), 1), dtype=bool)"
      ],
      "metadata": {
        "id": "mxyLQeCTZ2Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJfqIZzwbGae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}